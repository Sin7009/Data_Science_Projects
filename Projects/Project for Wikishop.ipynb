{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены!\n",
    "* Над этим проектом нужно будет еще немного поработать. Однако, изменения не должны занять много времени.\n",
    "* С радостью отвечу на твои вопросы, если они есть. Лучше всего их собрать в следующей ячейке. Жду новую версию проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Очистка\" data-toc-modified-id=\"Очистка-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Очистка</a></span></li><li><span><a href=\"#Лемматизация-WordNetLemmatizer\" data-toc-modified-id=\"Лемматизация-WordNetLemmatizer-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Лемматизация WordNetLemmatizer</a></span></li><li><span><a href=\"#Лемматизация-WordNetLemmatizer-+-pos_tag\" data-toc-modified-id=\"Лемматизация-WordNetLemmatizer-+-pos_tag-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Лемматизация WordNetLemmatizer + pos_tag</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#DecisionTreeClassifier\" data-toc-modified-id=\"DecisionTreeClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>DecisionTreeClassifier</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LGBMClassifier</a></span></li><li><span><a href=\"#Сравнение\" data-toc-modified-id=\"Сравнение-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Сравнение</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\knyaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\knyaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\knyaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "except: \n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92305</th>\n",
       "      <td>92396</td>\n",
       "      <td>REDIRECT Talk:Complete Music Update</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113677</th>\n",
       "      <td>113775</td>\n",
       "      <td>Further please note that the vitiated nature o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86350</th>\n",
       "      <td>86431</td>\n",
       "      <td>\"\\n\\n Your  Application \\n\\nDear Dean randall,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>3583</td>\n",
       "      <td>somthing something\\nDo You Hate A.Shetty787?  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156233</th>\n",
       "      <td>156392</td>\n",
       "      <td>article like this exist.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "92305        92396                REDIRECT Talk:Complete Music Update      0\n",
       "113677      113775  Further please note that the vitiated nature o...      0\n",
       "86350        86431  \"\\n\\n Your  Application \\n\\nDear Dean randall,...      0\n",
       "3583          3583  somthing something\\nDo You Hate A.Shetty787?  ...      0\n",
       "156233      156392                           article like this exist.      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак \"токсичный\" установлен для 10% комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    '''переводит в нижний регистр, оставляет только латиницу, удаляет stop_words'''\n",
    "    \n",
    "    stop_words = set(nltk_stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "    word_notstop_list = [w for w in word_list if not w in stop_words]\n",
    "    return ' '.join(word_notstop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102199</th>\n",
       "      <td>102296</td>\n",
       "      <td>Ok, so by that perhaps we could say women and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ok perhaps could say women minors still counti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139067</th>\n",
       "      <td>139219</td>\n",
       "      <td>\"\\n\\nImage copyright problem with Image:DSC019...</td>\n",
       "      <td>0</td>\n",
       "      <td>image copyright problem image dsc jpg thank up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153486</th>\n",
       "      <td>153643</td>\n",
       "      <td>| decline=Procedural decline: you will need to...</td>\n",
       "      <td>0</td>\n",
       "      <td>decline procedural decline need follow unblock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150828</th>\n",
       "      <td>150984</td>\n",
       "      <td>Follow the money trail</td>\n",
       "      <td>0</td>\n",
       "      <td>follow money trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102145</th>\n",
       "      <td>102242</td>\n",
       "      <td>. This behavior is in the Wikipedia app, not t...</td>\n",
       "      <td>0</td>\n",
       "      <td>behavior wikipedia app mobile website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "102199      102296  Ok, so by that perhaps we could say women and ...      0   \n",
       "139067      139219  \"\\n\\nImage copyright problem with Image:DSC019...      0   \n",
       "153486      153643  | decline=Procedural decline: you will need to...      0   \n",
       "150828      150984                             Follow the money trail      0   \n",
       "102145      102242  . This behavior is in the Wikipedia app, not t...      0   \n",
       "\n",
       "                                               clean_text  \n",
       "102199  ok perhaps could say women minors still counti...  \n",
       "139067  image copyright problem image dsc jpg thank up...  \n",
       "153486  decline procedural decline need follow unblock...  \n",
       "150828                                 follow money trail  \n",
       "102145              behavior wikipedia app mobile website  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    \n",
    "    '''Лемматизирует строку WordNetLemmatizer'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "data['wnl_text'] = data['clean_text'].apply(lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация WordNetLemmatizer + pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_lemm_text(text):\n",
    "    \n",
    "    '''Лемматизирует строку WordNetLemmatizer с учетом nltk.pos_tag'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "data['wnlpostag_text'] = data['clean_text'].apply(postag_lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>49827</th>\n",
       "      <th>104741</th>\n",
       "      <th>132034</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>49882</td>\n",
       "      <td>104838</td>\n",
       "      <td>132170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>\"\\n\\nMousercise is the title of several Disney...</td>\n",
       "      <td>\"\\n\\n How is this article U.S. biased?  \\n\\nI ...</td>\n",
       "      <td>LOL \\nhehe BJ means blow job LOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_text</th>\n",
       "      <td>mousercise title several disney productions gr...</td>\n",
       "      <td>article u biased think u bias template removed...</td>\n",
       "      <td>lol hehe bj means blow job lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnl_text</th>\n",
       "      <td>mousercise title several disney production gra...</td>\n",
       "      <td>article u biased think u bias template removed...</td>\n",
       "      <td>lol hehe bj mean blow job lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnlpostag_text</th>\n",
       "      <td>mousercise title several disney production gra...</td>\n",
       "      <td>article u bias think u bias template remove ar...</td>\n",
       "      <td>lol hehe bj mean blow job lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           49827   \\\n",
       "Unnamed: 0                                                  49882   \n",
       "text            \"\\n\\nMousercise is the title of several Disney...   \n",
       "toxic                                                           1   \n",
       "clean_text      mousercise title several disney productions gr...   \n",
       "wnl_text        mousercise title several disney production gra...   \n",
       "wnlpostag_text  mousercise title several disney production gra...   \n",
       "\n",
       "                                                           104741  \\\n",
       "Unnamed: 0                                                 104838   \n",
       "text            \"\\n\\n How is this article U.S. biased?  \\n\\nI ...   \n",
       "toxic                                                           0   \n",
       "clean_text      article u biased think u bias template removed...   \n",
       "wnl_text        article u biased think u bias template removed...   \n",
       "wnlpostag_text  article u bias think u bias template remove ar...   \n",
       "\n",
       "                                          132034  \n",
       "Unnamed: 0                                132170  \n",
       "text            LOL \\nhehe BJ means blow job LOL  \n",
       "toxic                                          1  \n",
       "clean_text        lol hehe bj means blow job lol  \n",
       "wnl_text           lol hehe bj mean blow job lol  \n",
       "wnlpostag_text     lol hehe bj mean blow job lol  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(3).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны корректно, молодец!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=12345, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['wnl_text'].values\n",
    "corpus_2 = data['wnlpostag_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Приводить тексты к юникоду не имеет смысла, так как они все на английском. Это может привести к падению ядра из-за увеличения объема занимаемой памяти.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Убрал перевод в юникод.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Векторизатор можно обучать только после разбиения выборки на части. При этом он должен быть обучен только на тренировочной части данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    corpus, \n",
    "    data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=123)\n",
    "\n",
    "features_train_2, features_test_2, target_train_2, target_test_2 = train_test_split(\n",
    "    corpus_2, \n",
    "    data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=123)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer()\n",
    "tf_idf = count_tf_idf.fit_transform(features_train)\n",
    "\n",
    "count_tf_idf_2 = TfidfVectorizer()\n",
    "tf_idf_2 = count_tf_idf_2.fit_transform(features_train_2)\n",
    "\n",
    "count_tt_idf = TfidfVectorizer()\n",
    "tt_idf = count_tf_idf.fit_transform(features_test)\n",
    "\n",
    "count_tt_idf_2 = TfidfVectorizer()\n",
    "tt_idf_2 = count_tf_idf_2.fit_transform(features_test_2)\n",
    "\n",
    "features_tfidf, features_test_tfidf, target_train, target_test = train_test_split(\n",
    "    tf_idf, target_train, test_size=0.2, random_state=123)\n",
    "\n",
    "features_tfidf_2, features_test_tfidf_2, target_train_2, target_test_2 = train_test_split(\n",
    "    tf_idf_2, target_train_2, test_size=0.2, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Надеюсь я правильно сделал. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.752 модель: LogisticRegression данные: wnl_text время работы модели: 3\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_1 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "model_1.mod = 'model_1'\n",
    "model_1.name = 'LogisticRegression'\n",
    "model_1.data = 'wnl_text'\n",
    "model_1.f1 = cross_val_score(model_1, features_tfidf, target_train, cv=kfold, scoring='f1')\n",
    "model_1.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_1.f1.mean()), \n",
    "      'модель:', model_1.name, \n",
    "      'данные:', model_1.data, \n",
    "      'время работы модели:', model_1.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.752 модель: LogisticRegression данные: wnlpostag_text время работы модели: 3\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_2 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "model_2.mod = 'model_2'\n",
    "model_2.name = 'LogisticRegression'\n",
    "model_2.data = 'wnlpostag_text'\n",
    "model_2.f1 = cross_val_score(model_2, features_tfidf_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_2.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_2.f1.mean()), \n",
    "      'модель:', model_2.name, \n",
    "      'данные:', model_2.data, \n",
    "      'время работы модели:', model_2.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.649 модель: DecisionTreeClassifier данные: wnl_text время работы модели: 283\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_3 = DecisionTreeClassifier(class_weight='balanced', random_state=123)\n",
    "\n",
    "model_3.mod = 'model_3'\n",
    "model_3.name = 'DecisionTreeClassifier'\n",
    "model_3.data = 'wnl_text'\n",
    "model_3.f1 = cross_val_score(model_3, features_tfidf, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_3.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_3.f1.mean()), \n",
    "      'модель:', model_3.name, \n",
    "      'данные:', model_3.data, \n",
    "      'время работы модели:', model_3.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.652 модель: DecisionTreeClassifier данные: wnlpostag_text время работы модели: 256\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_4 = DecisionTreeClassifier(class_weight='balanced', random_state=123)\n",
    "\n",
    "model_4.mod = 'model_4'\n",
    "model_4.name = 'DecisionTreeClassifier'\n",
    "model_4.data = 'wnlpostag_text'\n",
    "model_4.f1 = cross_val_score(model_4, features_tfidf_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_4.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_4.f1.mean()), \n",
    "      'модель:', model_4.name, \n",
    "      'данные:', model_4.data, \n",
    "      'время работы модели:', model_4.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.719 модель: LGBMClassifier 50 данные: wnl_text время работы модели: 41\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_5 = LGBMClassifier(n_estimators=50, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_5.mod = 'model_5'\n",
    "model_5.name = 'LGBMClassifier 50'\n",
    "model_5.data = 'wnl_text'\n",
    "model_5.f1 = cross_val_score(model_5, features_tfidf, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_5.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_5.f1.mean()), \n",
    "      'модель:', model_5.name, \n",
    "      'данные:', model_5.data, \n",
    "      'время работы модели:', model_5.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.724 модель: LGBMClassifier 50 данные: wnlpostag_text время работы модели: 37\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_6 = LGBMClassifier(n_estimators=50, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_6.mod = 'model_6'\n",
    "model_6.name = 'LGBMClassifier 50'\n",
    "model_6.data = 'wnlpostag_text'\n",
    "model_6.f1 = cross_val_score(model_6, features_tfidf_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_6.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_6.f1.mean()), \n",
    "      'модель:', model_6.name, \n",
    "      'данные:', model_6.data, \n",
    "      'время работы модели:', model_6.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.762 модель: LGBMClassifier 500 данные: wnl_text время работы модели: 240\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_7 = LGBMClassifier(n_estimators=500, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_7.mod = 'model_7'\n",
    "model_7.name = 'LGBMClassifier 500'\n",
    "model_7.data = 'wnl_text'\n",
    "model_7.f1 = cross_val_score(model_7, features_tfidf, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_7.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_7.f1.mean()), \n",
    "      'модель:', model_7.name, \n",
    "      'данные:', model_7.data, \n",
    "      'время работы модели:', model_7.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.724 модель: LGBMClassifier 500 данные: wnlpostag_text время работы модели: 36\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_8 = LGBMClassifier(n_estimators=500, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_8.mod = 'model_8'\n",
    "model_8.name = 'LGBMClassifier 500'\n",
    "model_8.data = 'wnlpostag_text'\n",
    "model_8.f1 = cross_val_score(model_5, features_tfidf_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_8.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_8.f1.mean()), \n",
    "      'модель:', model_8.name, \n",
    "      'данные:', model_8.data, \n",
    "      'время работы модели:', model_8.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={}\n",
    "for i in model_list:\n",
    "    b={}    \n",
    "    b['model']=i.name\n",
    "    b['data']=i.data\n",
    "    b['f1_score']=i.f1.mean()\n",
    "    b['cross_val_time']=i.time\n",
    "    a[i.mod] = b\n",
    "\n",
    "final_table = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cross_val_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.752217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.751692</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.648918</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.651795</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.719305</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.723829</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.761603</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.723829</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model            data  f1_score cross_val_time\n",
       "model_1      LogisticRegression        wnl_text  0.752217              3\n",
       "model_2      LogisticRegression  wnlpostag_text  0.751692              3\n",
       "model_3  DecisionTreeClassifier        wnl_text  0.648918            283\n",
       "model_4  DecisionTreeClassifier  wnlpostag_text  0.651795            256\n",
       "model_5       LGBMClassifier 50        wnl_text  0.719305             41\n",
       "model_6       LGBMClassifier 50  wnlpostag_text  0.723829             37\n",
       "model_7      LGBMClassifier 500        wnl_text  0.761603            240\n",
       "model_8      LGBMClassifier 500  wnlpostag_text  0.723829             36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что попробовал разные модели в этом шаге!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637333333333334\n"
     ]
    }
   ],
   "source": [
    "model_7.fit(features_tfidf, target_train)\n",
    "model_7.predicted = model_7.predict(features_test_tfidf)\n",
    "model_7.test_f1 = f1_score(target_test, model_7.predicted)\n",
    "print(model_7.test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> На тестовой выборке нужно измерить только одну – лучшую модель. Сравнение моделей нужно провести на кросс-валидации/валидационной выборке.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Сделано! Оставил только одну модель с лучшими метриками! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие результаты показала модель LGBMClassifier с n_estimators=500 и логистическая регрессия на менее обработанных данных (лемматизация без учета части речи). При этом логистическая регрессия значительно быстрее. Увеличение метрик возможно за счет подбора более результативных вариантов предобработки, перебора гиперпараметров и использования более серьезных специализированных инструментов, но такие мероприятия более ресурсоёмки (требуют использования более произодительных вычислительных мощностей или увеличения времени обработки задачи).\n",
    "\n",
    "Установленное значение метрики f1 (0.75) было достигнуто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть вывод в конце проекта!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2196,
    "start_time": "2023-01-26T12:52:32.584Z"
   },
   {
    "duration": 1949,
    "start_time": "2023-01-26T12:52:34.782Z"
   },
   {
    "duration": 35,
    "start_time": "2023-01-26T12:52:36.732Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-26T12:52:36.769Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-26T12:52:36.792Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-26T12:52:36.816Z"
   },
   {
    "duration": 20666,
    "start_time": "2023-01-26T12:52:36.844Z"
   },
   {
    "duration": 45,
    "start_time": "2023-01-26T12:52:57.511Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-26T12:52:57.558Z"
   },
   {
    "duration": 19330,
    "start_time": "2023-01-26T12:52:57.583Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-26T12:53:16.915Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-26T12:53:16.924Z"
   },
   {
    "duration": 587,
    "start_time": "2023-01-26T12:53:16.946Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-26T12:53:17.536Z"
   },
   {
    "duration": 66,
    "start_time": "2023-01-30T13:16:17.529Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
